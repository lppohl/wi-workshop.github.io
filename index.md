---
title: Home
layout: page
---


# Social Science and Language Models <br>
### Methods and theory to responsible research on and with Language technologies
<br>
<p> In recent years, language models have seen improved performance in tasks like translation, sorting, and text generation, which has led to their integration into a variety of fields, such as medical contexts, software engineering but also social science. Parallel to this technological proliferation, the emerging field of Responsible AI research has revealed various socio-technical biases in language models which result in discrimination based on attributes such as ethnicity, gender, and more. These findings force both social scientists and computer scientists who are integrating these tools into their research, to reflect how they can detect and mitigate potentially  biased outcomes. By doing so, they contribute to an expanding body of literature that critiques how discrimination is conceptualized, how bias measurements are operationalized, and how existing bias benchmarks are constructed. These issues stem from a lack of genuine interdisciplinary collaboration between NLP researchers and researchers from various social science disciplines.
</p>
This hybrid workshop is meant to provide the space for interdisciplinary exchange toward responsible research on and with language models.

------

### Event Details

**Date:** 03./04.04.2025

**Deadline for Abstract submission:** 02.03.2025

**Location:** [Weizenbaum Institut](https://www.weizenbaum-institut.de/) and hybrid

**Registration to attend the workshop** [Registration Form](https://limesurvey.weizenbaum-institut.de/index.php/776613?lang=en)

------

### Speakers

**Zeerak Talat**

{% include figure.html img="picture_zeerak.jpg" alt="a picture of Zeerak Talat, sitting cacually" caption="" width="50%" %}

Zeerak Talat is a Chancellor’s Fellow (~Assistant Professor) in Responsible Machine Learning and Artificial Intelligence at the Centre for Technomoral Futures and Institute for Language, Cognition, and Computing (ILCC) in the School of Informatics at the University of Edinburgh. Zeerak is also a Faculty Fellow at DAIR (Distributed AI Research Institute). They work on the intersection between machine learning, science and technology studies,
and media studies. Zeerak’s research seeks to examine how machine learning systems interact with our societies and the downstream effects of introducing machine learning to our society viewed through the lens of content moderation. Zeerak is one of the founders and co-organisers of the Workshop on Online Abuse and Harms, and currently serves as the ACL Workshop Officer, the president of the Broad Interest Group on Equity in ACL (EquiCL); and sits on the university-wide Information Services Group Ethics Board at the University of Edinburgh.

Link to website:  [https://zeerak.org](https://zeerak.org) 
<br>

**Flor Miriam Plaza del Arco**

{% include figure.html img="photo_flor_plaza.png" alt="a portrait picture of Flor Miriam Plaza del Arco" caption="" width="50%" %}

Flor is an Assistant Professor at the Leiden Institute of Advanced Computer Science (LIACS). She was previously a postdoctoral researcher at Bocconi University’s MilaNLP lab. Her research lies at the intersection of language, computation, and society. She investigates how large language models represent and interpret human emotions, specifically exploring whether these models perpetuate biases, stereotypes, or harmful language across different cultural and social contexts. She collaborates with social scientists to provide an integrated view of these issues and promotes fairness and cultural sensitivity in AI systems.

She has co-organized notable events, including the 8th Workshop on Online Abuse and Harms at NAACL 2024 and the Tutorial on Countering Hateful and Offensive Speech Online at EMNLP 2024. She also co-organized the 36th, 37th, and 39th editions of the Spanish Society for Natural Language Processing Conference (SEPLN). She is co-organizing the 9th Workshop on Online Abuse and Harms at ACL 2025.

Link to website:  [https://fmplaza.github.io](https://fmplaza.github.io) 

